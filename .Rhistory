<<<<<<< HEAD
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
# get books by authors
author.end.point <- 'best-sellers/history.json?'
i <- 2
while (i <= 2) {
author <- authors[[i, 'author']]
author.1.url <- paste0(base.url, author.end.point,
'author=', author, '&', 'api-key=', key)
author.1.url <- URLencode(author.1.url)
author.1.results <- fromJSON(author.1.url)
flatten.author.1 <- flatten(author.1.results$results)
num.books.by.author <- as.numeric(author.1.results$num_results)
# get history
book.rank.history <- flatten.author.1[[10]]
# get num weeks
j <- 2
l <- list();
while(j <= num.books.by.author) {
weeks.on.list <- book.rank.history[[j]]
total.weeks <- weeks.on.list %>% summarise(weeks = sum(weeks_on_list))
l[[j]] <- total.weeks
j <- j + 1
}
i <- i + 1
}
books <- flatten.author.1$title
books.by.author <- data.frame(author, books, l)
############### things to work on ###############
# make widget to retrieve date from user input
# replace empty rows with zeros
# create dataframe for multiple authors
# load api key file
library(jsonlite)
library(dplyr)
# get data with API
base.url <- 'http://api.nytimes.com/svc/books/v3/lists/'
overview.end.point <- 'overview.json?'
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-03-12'
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
# get books by authors
author.end.point <- 'best-sellers/history.json?'
i <- 3
while (i <= 3) {
author <- authors[[i, 'author']]
author.1.url <- paste0(base.url, author.end.point,
'author=', author, '&', 'api-key=', key)
author.1.url <- URLencode(author.1.url)
author.1.results <- fromJSON(author.1.url)
flatten.author.1 <- flatten(author.1.results$results)
num.books.by.author <- as.numeric(author.1.results$num_results)
# get history
book.rank.history <- flatten.author.1[[10]]
# get num weeks
j <- 2
l <- list();
while(j <= num.books.by.author) {
weeks.on.list <- book.rank.history[[j]]
total.weeks <- weeks.on.list %>% summarise(weeks = sum(weeks_on_list))
l[[j]] <- total.weeks
j <- j + 1
}
i <- i + 1
}
books <- flatten.author.1$title
books.by.author <- data.frame(author, books, l)
############### things to work on ###############
# make widget to retrieve date from user input
# replace empty rows with zeros
# create dataframe for multiple authors
# load api key file
library(jsonlite)
library(dplyr)
# get data with API
base.url <- 'http://api.nytimes.com/svc/books/v3/lists/'
overview.end.point <- 'overview.json?'
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-03-12'
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
# get books by authors
author.end.point <- 'best-sellers/history.json?'
i <- 4
while (i <= 4) {
author <- authors[[i, 'author']]
author.1.url <- paste0(base.url, author.end.point,
'author=', author, '&', 'api-key=', key)
author.1.url <- URLencode(author.1.url)
author.1.results <- fromJSON(author.1.url)
flatten.author.1 <- flatten(author.1.results$results)
num.books.by.author <- as.numeric(author.1.results$num_results)
# get history
book.rank.history <- flatten.author.1[[10]]
# get num weeks
j <- 2
l <- list();
while(j <= num.books.by.author) {
weeks.on.list <- book.rank.history[[j]]
total.weeks <- weeks.on.list %>% summarise(weeks = sum(weeks_on_list))
l[[j]] <- total.weeks
j <- j + 1
}
i <- i + 1
}
books <- flatten.author.1$title
books.by.author <- data.frame(author, books, l)
############### things to work on ###############
# make widget to retrieve date from user input
# replace empty rows with zeros
# create dataframe for multiple authors
# load api key file
library(jsonlite)
library(dplyr)
# get data with API
base.url <- 'http://api.nytimes.com/svc/books/v3/lists/'
overview.end.point <- 'overview.json?'
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-03-12'
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
# get books by authors
author.end.point <- 'best-sellers/history.json?'
i <- 5
while (i <= 5) {
author <- authors[[i, 'author']]
author.1.url <- paste0(base.url, author.end.point,
'author=', author, '&', 'api-key=', key)
author.1.url <- URLencode(author.1.url)
author.1.results <- fromJSON(author.1.url)
flatten.author.1 <- flatten(author.1.results$results)
num.books.by.author <- as.numeric(author.1.results$num_results)
# get history
book.rank.history <- flatten.author.1[[10]]
# get num weeks
j <- 2
l <- list();
while(j <= num.books.by.author) {
weeks.on.list <- book.rank.history[[j]]
total.weeks <- weeks.on.list %>% summarise(weeks = sum(weeks_on_list))
l[[j]] <- total.weeks
j <- j + 1
}
i <- i + 1
}
books <- flatten.author.1$title
books.by.author <- data.frame(author, books, l)
############### things to work on ###############
# make widget to retrieve date from user input
# replace empty rows with zeros
# create dataframe for multiple authors
# load api key file
library(jsonlite)
library(dplyr)
# get data with API
base.url <- 'http://api.nytimes.com/svc/books/v3/lists/'
overview.end.point <- 'overview.json?'
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-03-12'
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
week <- list[[23]] %>% select(weeks_on_list)
# get books by authors
author.end.point <- 'best-sellers/history.json?'
View(week)
############### things to work on ###############
# make widget to retrieve date from user input
# replace empty rows with zeros
# create dataframe for multiple authors
# load api key file
library(jsonlite)
library(dplyr)
# get data with API
base.url <- 'http://api.nytimes.com/svc/books/v3/lists/'
overview.end.point <- 'overview.json?'
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-03-12'
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
week <- list[['weeks_on_list']] %>% select(weeks_on_list)
# get books by authors
author.end.point <- 'best-sellers/history.json?'
i <- 5
while (i <= 5) {
author <- authors[[i, 'author']]
author.1.url <- paste0(base.url, author.end.point,
'author=', author, '&', 'api-key=', key)
author.1.url <- URLencode(author.1.url)
author.1.results <- fromJSON(author.1.url)
flatten.author.1 <- flatten(author.1.results$results)
num.books.by.author <- as.numeric(author.1.results$num_results)
# get history
book.rank.history <- flatten.author.1[[10]]
# get num weeks
j <- 2
l <- list();
while(j <= num.books.by.author) {
weeks.on.list <- book.rank.history[[j]]
total.weeks <- weeks.on.list %>% summarise(weeks = sum(weeks_on_list))
l[[j]] <- total.weeks
j <- j + 1
}
i <- i + 1
}
books <- flatten.author.1$title
books.by.author <- data.frame(author, books, l)
############### things to work on ###############
# make widget to retrieve date from user input
# replace empty rows with zeros
# create dataframe for multiple authors
# load api key file
library(jsonlite)
library(dplyr)
# get data with API
base.url <- 'http://api.nytimes.com/svc/books/v3/lists/'
overview.end.point <- 'overview.json?'
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-03-12'
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
week <- list[['weeks_on_list']] %>% select(weeks_on_list)
View(weeks.on.list)
View(week)
############### things to work on ###############
# make widget to retrieve date from user input
# replace empty rows with zeros
# create dataframe for multiple authors
# load api key file
library(jsonlite)
library(dplyr)
# get data with API
base.url <- 'http://api.nytimes.com/svc/books/v3/lists/'
overview.end.point <- 'overview.json?'
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-03-12'
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
week <- list[['weeks_on_list']] %>% select(weeks_on_list)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
week <- list[[23]] %>% select(weeks_on_list)
authors <- list[[4]] %>% select(author)
View(authors)
list[[23]]
list[[4]]
print(list[[23]])
weeks <- list[[23]] %>% select('weeks_on_list')
View(weeks)
# store authors into a dataframe
list <- flattened[[9]]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
weeks <- list[[17]] %>% select(publisher)
View(week)
weeks <- list[[23]] %>% select(weeks_on_list)
View(weeks)
weeks <- list[[23]]
flattened <- flatten(results$results$lists)
View(flattened)
list <- flattened[['books']]
list <- flattened[['books']]
authors <- list[['author']] %>% select(author)
list <- flattened[['books']]
View(authors)
list <- flattened[['books']]
authors <- list[['author']] %>% select(author)
authors <- list[[4]] %>% select(author)
View(authors)
############### things to work on ###############
# make widget to retrieve date from user input
# replace empty rows with zeros
# create dataframe for multiple authors
# load api key file
library(jsonlite)
library(dplyr)
# get data with API
base.url <- 'http://api.nytimes.com/svc/books/v3/lists/'
overview.end.point <- 'overview.json?'
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-04-12'
full.url <- paste0(base.url, overview.end.point, 'published_date=', date, '&', 'api-key=', key)
results <- fromJSON(full.url)
# store data into a dataframe
flattened <- flatten(results$results$lists)
# store authors into a dataframe
list <- flattened[['books']]
authors <- list[[4]] %>% select(author)
num.authors <- summarise(authors, count = n())
weeks <- list[[23]] %>% select(weeks_on_list)
key <- '2f6f47e7312b49239cd7617099bee3fe'
library(jsonlite)
library(dplyr)
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <- '2016-02-14'
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=key, "published_date"=date)
response <- GET(base.url, query = query.params)
response <- GET(base.url, query = query.params)
library(jsonlite)
response <- GET(base.url, query = query.params)
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <-'2016-02-14'
OneDateInfo <- function (date, key) {
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=key, "published_date"=date)
response <- GET(base.url, query = query.params)
response <- GET(base.url, query = query.params)
response <- GET(base.url, query = query.params)
key <- '2f6f47e7312b49239cd7617099bee3fe'
date <-'2016-02-14'
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=key, "published_date"=date)
response <- GET(base.url, query = query.params)
results <- as.data.frame(fromJSON(full.url))
flattened <- flatten(results$results.lists.books)
flattened <- flatten(results$results.lists.books[[23]])
View(flattened)
flattened <- results$results.lists.books[[23]]
=======
body <- content(response, "text")
results <- fromJSON(body)
flat <- flatten(results$results)
name <- flat[x,"name"]
return(name)
}
#get an id
SelectedID <- function(x,state) {
base.url <- paste(
"https://api.propublica.org/congress/v1/members/house/", state, "/current.json", sep = "")
response <- GET(base.url,add_headers("X-API-Key" = api.key.propublica))
body <- content(response, "text")
results <- fromJSON(body)
flat <- flatten(results$results)
id<- flat[x,"id"]
return(id)
}
#Age
AgeR <- function(id) {
base.url <- paste("https://api.propublica.org/congress/v1/members/", id, ".json", sep = "")
response <- GET(base.url,add_headers("X-API-Key" = api.key.propublica))
body <- content(response, "text")
results <- fromJSON(body)
flat2 <- flatten(results$results)
age.number <- round(
as.numeric(
difftime(
as.Date(Sys.Date()),as.Date(flat2$date_of_birth),unit="weeks")/52.25, digits=0))
return(age.number)
}
#Twitter account
TwitterR<- function(id) {
base.url <- paste("https://api.propublica.org/congress/v1/members/", id, ".json", sep = "")
response <- GET(base.url,add_headers("X-API-Key" = api.key.propublica))
body <- content(response, "text")
results <- fromJSON(body)
flat2 <- flatten(results$results)
twitter.id<- flat2$twitter_account
url<-paste0("https://twitter.com/",twitter.id,sep="")
return(url)
}
VoteR <- function(id) {
base.url <- paste("https://api.propublica.org/congress/v1/members/", id, "/votes.json", sep = "")
response <- GET(base.url,add_headers("X-API-Key" = api.key.propublica))
body <- content(response, "text")
results <- fromJSON(body)
flat3 <- flatten(results$results)
vote.record<- as.data.frame(flat3$votes)
flat4 <-flatten(vote.record)
vote.times <- flat4 %>%
select(position) %>%
nrow
vote.percentage.agreed.1 <- flat4 %>%
filter(result=="Passed"& position =="Yes") %>%
nrow()
vote.percentage.agreed.2 <- flat4 %>%
filter(result=="Failed"& position=="No") %>%
nrow()
vote.agreed.percentage <- paste((vote.percentage.agreed.1+vote.percentage.agreed.2)/vote.times*100, "%", sep="")
return(vote.agreed.percentage)
}
VoteNumber <- function(id) {
base.url <- paste("https://api.propublica.org/congress/v1/members/", id, "/votes.json", sep = "")
response <- GET(base.url,add_headers("X-API-Key" = api.key.propublica))
body <- content(response, "text")
results <- fromJSON(body)
flat3 <- flatten(results$results)
vote.record<- as.data.frame(flat3$votes)
flat4 <-flatten(vote.record)
vote.times <- flat4 %>%
select(position) %>%
nrow
return(vote.times)}
library(jsonlite)
library(dplyr)
library(httr)
setwd("~/Desktop/INFO201/a5-report-yjia757")
source("api-keys.R")
FindPoliticalR <- function(address) {
base.url <- 'https://www.googleapis.com/civicinfo/v2/representatives'
query.params <- list(address=address, key = api.key.civic.info)
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
flat.basic <- flatten(results$officials)
flat.more <- flatten (results$offices)
names(flat.more)[names(flat.more) == "name"] <- "position"
names(flat.basic)[names(flat.basic) == "photo"] <- "photoUrl"
flat.basic$emails[flat.basic$emails == "NULL"] <- "Not available"
flat.basic$photo[is.na(flat.basic$photo)] <- "Not available"
ExtendRow <- by(flat.more, 1:nrow(flat.more), function(row) {
vector.number <-unlist(row["officialIndices"])
new_data <- row[rep(1, each = length(vector.number)),]
new_data$officialIndices <- vector.number
return(new_data)
})
expand.flat.more <- do.call(rbind,ExtendRow)
flat.basic$officialIndices <- as.numeric(rownames(flat.basic)) - 1
combined.flat <-left_join(flat.basic,expand.flat.more,by="officialIndices")
new.combined.flat <- combined.flat[,c("name","urls","position", "party", "emails","phones","photo")]
return(new.combined.flat)}
StateInput <- function (address) {
base.url <- 'https://www.googleapis.com/civicinfo/v2/representatives'
query.params <- list(address=address, key = api.key.civic.info)
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
address.input.info <- as.data.frame(results$normalizedInput,stringsAsFactors=FALSE)
state.abbr <-address.input.info$state
return(state.abbr)}
setwd("~/Desktop/Autumn2017/INFO201/Final/personal_test")
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = ufU9flOS78IvLt0hfuxKA,id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
library(jsonlite)
library(dplyr)
library(httr)
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = ufU9flOS78IvLt0hfuxKA,id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = ufU9flOS78IvLt0hfuxKA,id= "Goodreads Author id")
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
body <- json(content(response, "text"))
list.data <-xmlTolist(body)
install.packages("XML")
library("XML")
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
list.data <-xmlTolist(body)
results <- fromJSON(body)
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
list.data <-xmlTolist(body)
list.data <-xmlToList(body)
results <- fromJSON(body)
results <- fromJSON(list.data)
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
list.data <-xmlToList(body)
list.data
results <- fromJSON(list.data)
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
list.data <-xmlToList(body)
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
list.data <-xmlToList(body)
jason.data <-toJSON(list.data)
results <- fromJSON(jason.data)
base.url <- 'https://www.goodreads.com/author/show.xml'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
list.data <-xmlToList(body)
jason.data <-toJSON(list.data)
results <- fromJSON(jason.data)
results <- fromJSON(jason.data)
results
base.url <- 'https://www.goodreads.com/author/show'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
list.data <-xmlToList(body)
jason.data <-toJSON(list.data)
results <- fromJSON(jason.data)
results
base.url <- 'https://www.goodreads.com/author/show'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id",format=son)
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
base.url <- 'https://www.goodreads.com/book/show.FORMAT '
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "A Goodreads internal book_id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
base.url <- 'https://www.goodreads.com/book/show.'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "A Goodreads internal book_id")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
base.url <- 'https://www.goodreads.com/book/show.FORMAT'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "A Goodreads internal book_id",text_only=FALSE)
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
base.url <- 'https://www.goodreads.com/author/show'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id",format=json)
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
base.url <- 'https://www.goodreads.com/author/show'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",id= "Goodreads Author id",format="json")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
base.url <- 'https://www.goodreads.com/book/review_counts.json'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",isbns=0596009208)
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
result <-fromJSON(https://www.goodreads.com/book/review_counts.json?key={apikey}&isbns=0596009208,0596517742)
result <-fromJSON(https://www.goodreads.com/book/review_counts.json?key={apikey}&isbns=0596009208,0596517742)
result <-fromJSON(https:/www.goodreads.com/book/review_counts.json?key={apikey}&isbns=0596009208,0596517742)
result <-fromJSON("https://www.goodreads.com/book/review_counts.json?key={apikey}&isbns=0596009208,0596517742")
result <-fromJSON("https://www.goodreads.com/book/review_counts.json?key=ufU9flOS78IvLt0hfuxKA&isbns=0596009208,0596517742")
result
base.url <- 'https://www.goodreads.com/book/review_counts.json'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",isbns="0596009208")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
results
results <- as.data(fromJSON(body))
results <- as.data.frame(fromJSON(body))
View(results)
base.url <- 'https://www.goodreads.com/book/review_counts.json'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",isbns="0596009208")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
results
base.url <- 'https://www.goodreads.com/book/review_counts.json'
query.params <- list(key = "ufU9flOS78IvLt0hfuxKA",isbns="0596009208")
response <- GET(base.url, query = query.params)
body <- content(response, "text")
results <- fromJSON(body)
as.data.frame(results)
b <-as.data.frame(results)
View(b)
PriceInfo <-by(combined.df,1:nrow(combined.df),function(newrow){
every <-as.data.frame(newrow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagnet")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price) })
all.price <-do.call(rbind,PriceInfo)
PriceInfo <-by(combined.df,1:nrow(combined.df),function(newrow){
every <-as.data.frame(newrow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagnet")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price) })
library(httr)
library(jsonlite)
library(tidytext)
library(dplyr)
library(stringr)
library(ggplot2)
library(rvest)
library(curl)
source("api.key.R")
setwd("~/Desktop/Autumn2017/INFO201/FinalProject/FinalProject-Goodreads")
>>>>>>> 012268d2e44cff24062c79f818516d218ed9a529
library(httr)
library(jsonlite)
library(tidytext)
library(dplyr)
library(stringr)
library(ggplot2)
library(rvest)
library(curl)
source("api.key.R")
<<<<<<< HEAD
UserCombinedInfo <- function(startdate,enddate) {
time.period <-seq(as.Date("2016-03-12"), as.Date("2016-03-14"), by=1)
OneDateInfo <- function (date) {
key <- "2f6f47e7312b49239cd7617099bee3fe"
=======
time.period <-seq(as.Date("2016-03-12"), as.Date("2016-03-20"), by=1)
OneDateInfo <- function (date) {
>>>>>>> 012268d2e44cff24062c79f818516d218ed9a529
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=yiran.api.key, "published_date"=date)
response <- GET(base.url, query = query.params)
body <-content (response, "text")
results <-as.data.frame(fromJSON(body))
UsefulInfo <- by(results,1:nrow(results),function(row){
each <-as.data.frame(row$results.lists.books)
return(each)
})
all.useful <-do.call(rbind,UsefulInfo)
}
<<<<<<< HEAD
}
results <-as.data.frame(fromJSON(body))
date <- '2016-02-02'
key <- "2f6f47e7312b49239cd7617099bee3fe"
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=yiran.api.key, "published_date"=date)
response <- GET(base.url, query = query.params)
body <-content (response, "text")
results <-as.data.frame(fromJSON(body))
date <- '2016-02-02'
key <- "2f6f47e7312b49239cd7617099bee3fe"
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=key, "published_date"=date)
response <- GET(base.url, query = query.params)
body <-content (response, "text")
results <-as.data.frame(fromJSON(body))
results$results.lists.books
is.list(results$results.lists.books)
list <- results$results.lists.books
=======
combined.df <-lapply(time.period,OneDateInfo)
combined.df <-as.data.frame(do.call(rbind,combined.df))
combined.df <-unique(combined.df) %>%
select(title, weeks_on_list, buy_links)
PriceInfo <-by(combined.df,1:nrow(combined.df),function(newrow){
every <-as.data.frame(newrow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagnet")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price) })
all.price <-do.call(rbind,PriceInfo)
View(all.price)
nrow(combined.df)
View(all.price)
all.price <-do.call(rbind,PriceInfo,na.rm=FALSE)
PriceInfo
arow <-combined.df[315,]
every <-as.data.frame(arow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagnet")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
PriceInfo <- function (newrow) {
every <-as.data.frame(arow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
test
every <-as.data.frame(arow$buy_links)
price.url <-every[3,2]
price.url
every
every <-as.data.frame(arow$buy_links)
View(every)
PriceInfo <- function (newrow) {
every <-as.data.frame(newrow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
every <-arow["buy_links"]
eery
every
class(every)
PriceInfo <- function (newrow) {
every <-arow["buy_links"]
all.price.url <-as.data.frame(every[1,1])
bn.price.url <-all.price.url[3,2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
test
PriceInfo <- function (newrow) {
every <-newrow["buy_links"]
all.price.url <-as.data.frame(every[1,1])
bn.price.url <-all.price.url[3,2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
every <-arow["buy_links"]
every
View(every)
PriceInfo <- function (newrow) {
every <-as.data.frame(arow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagnet")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price) })
PriceInfo <- function (newrow) {
every <-as.data.frame(arow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagnet")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price) }
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
PriceInfo <- function (newrow) {
every <-as.data.frame(newrow$buy_links)
price.url <-every[3,2]
page <-read_html(GET(price.url,user_agent("myagnet")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price) }
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
PriceInfo <- function (newrow) {
every <-arow["buy_links"]
all.price.url <-as.data.frame(every[1,1])
bn.price.url <-all.price.url[3,2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
PriceInfo <- function (newrow) {
every <-newrow["buy_links"]
all.price.url <-as.data.frame(every[1,1])
bn.price.url <-all.price.url[3,2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
every <-arow["buy_links"]
class(every)
all.price.url <-as.data.frame(every$buy_links)
all.price.url
View(all.price.url)
bn.price.url <-all.price.url[name="Barnes and Noble",2]
bn.price.url <-all.price.url[name=="Barnes and Noble",2]
bn.price.url <-all.price.url[all.price.url$name=="Barnes and Noble",2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
PriceInfo <- function (newrow) {
every <-newrow["buy_links"]
all.price.url <-as.data.frame(every$buy_links)
bn.price.url <-all.price.url[all.price.url$name=="Barnes and Noble",2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
all.price.url <-as.data.frame(every["buy_links"])
View(all.price.url)
every <-newrow["buy_links"]
every <-arow["buy_links"]
View(every)
all.price.url <-every["buy_links"]
View(all.price)
View(all.price.url)
all.price.url <-every$buy_links
PriceInfo <- function (newrow) {
every <-newrow["buy_links"]
all.price.url <-as.data.frame(every$buy_links)
bn.price.url <-all.price.url[all.price.url$name=="Barnes and Noble",2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
is.recursive(every$buy_links)
is.atomic(every$buy_links)
PriceInfo <- function (newrow) {
every <-newrow["buy_links"]
all.price.url <-as.data.frame(every$buy_links)
bn.price.url <-all.price.url[all.price.url$name=="Barnes and Noble",2]
page <-read_html(GET(price.url,user_agent("myagent")))
price <-page %>% html_nodes('#pdp-cur-price') %>% html_text()
price <-as.numeric(sub('\\$','',as.character(price)))
return(price)
}
test <-do.call(rbind,lapply(1:nrow(combined.df),PriceInfo))
every$buy_links
>>>>>>> 012268d2e44cff24062c79f818516d218ed9a529
library(httr)
library(jsonlite)
library(tidytext)
library(dplyr)
library(stringr)
library(ggplot2)
library(rvest)
library(curl)
<<<<<<< HEAD
#source("api.key.R")
date <- '2016-02-02'
key <- "2f6f47e7312b49239cd7617099bee3fe"
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=key, "published_date"=date)
response <- GET(base.url, query = query.params)
body <-content (response, "text")
results <-as.data.frame(fromJSON(body))
list <- results$results.lists.books
list <- as.data.frame(results$results.lists.books)
View(list)
list.1 <- list %>% select(author,title,weeks_on_list)
list.2 <- list %>% select(author.8)
list.2
row.names(list)
colnames(list)
t(list)
View(list)
list <- as.data.frame(results$results.lists.books)
t(list)
View(list.1)
length(results$results.lists.books)
datalist <- list()
for (i in 1:5) {
dat <- data.frame(x = rnorm(10), y = runif(10))
dat$i <- i
datalist[[i]] <- dat
}
list <- as.data.frame(results$results.lists.books)
info_total <- list %>% select(author,title,weeks_on_list)
datalist <- list()
for (i in 2:5) {
info <- list %>% select(author, title, weeks_on_list)
df <- data.frame(info)
df_total <- rbind(info_total, df)
}
View(info_total)
View(df_total)
View(list)
colnames(list)[which(names(list) == "author1")] <- "author"
View(list)
colnames(list)[which(names(list) == "author.1")] <- "author"
info <- list %>% select(author, title, weeks_on_list)
list <- as.data.frame(results$results.lists.books)
colnames(list)[which(names(list) == "author.1")] <- "author"
colnames(list)[which(names(list) == "title.1")] <- "title"
colnames(list)[which(names(list) == "weeks_on_list.1")] <- "weeks_on_list"
info <- list %>% select(author, title, weeks_on_list)
datalist <- list()
for (i in 2:5) {
info <- list %>% select(author, title, weeks_on_list)
df <- data.frame(info)
info_total <- rbind(info_total, df)
}
info <- list %>% select(author, title, weeks_on_list)
info <- list %>% select(author.2, title.2, weeks_on_list.2)
list <- as.data.frame(results$results.lists.books)
colnames(list)[which(names(list) == "author.1")] <- "author"
colnames(list)[which(names(list) == "title.1")] <- "title"
colnames(list)[which(names(list) == "weeks_on_list.1")] <- "weeks_on_list"
info <- list %>% select(author.2, title.2, weeks_on_list.2)
date <- '2016-02-02'
key <- "2f6f47e7312b49239cd7617099bee3fe"
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=key, "published_date"=date)
response <- GET(base.url, query = query.params)
body <-content (response, "text")
results <-as.data.frame(fromJSON(body))
list <- as.data.frame(results$results.lists.books)
colnames(list)[which(names(list) == "author.1")] <- "author"
colnames(list)[which(names(list) == "title.1")] <- "title"
colnames(list)[which(names(list) == "weeks_on_list.1")] <- "weeks_on_list"
info <- list %>% select(author.2, title.2, weeks_on_list.2)
list <- as.data.frame(results$results.lists.books)
View(list.2)
View(list.1)
View(list.2)
info2 <- list %>% select(author.2, title.2, weeks_on_list.2)
View(info2)
info2 <- list %>% select(author, title, weeks_on_list)
View(info2)
View(list)
list <- as.data.frame(results$results.lists.books)
colnames(list)[which(names(list) == "author.1")] <- "author"
colnames(list)[which(names(list) == "title.1")] <- "title"
colnames(list)[which(names(list) == "weeks_on_list.1")] <- "weeks_on_list"
info2 <- list %>% select(author, title, weeks_on_list)
list <- as.data.frame(results$results.lists.books)
colnames(list)[which(names(list) == "author.1")] <- "author"
colnames(list)[which(names(list) == "title.1")] <- "title"
colnames(list)[which(names(list) == "weeks_on_list.1")] <- "weeks_on_list"
info3 <- list %>% select(author, title, weeks_on_list)
=======
source("api.key.R")
time.period <-seq(as.Date("2016-03-12"), as.Date("2016-03-20"), by=1)
OneDateInfo <- function (date) {
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=yiran.api.key, "published_date"=date)
response <- GET(base.url, query = query.params)
body <-content (response, "text")
results <-as.data.frame(fromJSON(body))
UsefulInfo <- by(results,1:nrow(results),function(row){
each <-as.data.frame(row$results.lists.books)
return(each)
})
all.useful <-do.call(rbind,UsefulInfo)
}
combined.df <-lapply(time.period,OneDateInfo)
combined.df <-as.data.frame(do.call(rbind,combined.df))
combined.df <-unique(combined.df) %>%
select(title, weeks_on_list, buy_links)
bn.price.url <-all.price.url[all.price.url$name=="Barnes and Noble",2]
time.period <-seq(as.Date("2016-03-12"), as.Date("2016-03-20"), by=1)
OneDateInfo <- function (date) {
base.url <-"https://api.nytimes.com/svc/books/v3/lists/overview.json"
query.params <-list("api-key"=yiran.api.key, "published_date"=date)
response <- GET(base.url, query = query.params)
body <-content (response, "text")
results <-as.data.frame(fromJSON(body))
UsefulInfo <- by(results,1:nrow(results),function(row){
each <-as.data.frame(row$results.lists.books)
return(each)
})
all.useful <-do.call(rbind,UsefulInfo)
}
combined.df <-lapply(time.period,OneDateInfo)
combined.df <-as.data.frame(do.call(rbind,combined.df))
combined.df <-unique(combined.df) %>%
select(title, weeks_on_list, buy_links)
combined.df
>>>>>>> 012268d2e44cff24062c79f818516d218ed9a529
